## 엔지니어가 배워야할 금융시스템의 지식과 기술

###제 3장 금융비지니스를 지원하는 데잍사이언스 기법

1. 구조화된 데이터는 전자적으로 기록된 시점에서 RDB처럼 행(레코드)과 열(속성)을 가진 표 형식 데이터를 말한다. 일반적인 표 형식 데이터는 여러 속성을 가진 레코드으 집합으로 구성된다. 또한 이 속성의 집합을 가리켜 데이터의 성질을 나타내는 '특징량' 또는 '특징벡터' 라고 한다. 

2. 반면 비구조화 데이터란 데이터로서 전자적으로 기록된 시점에서는 표 형식을 취하지 않는 텍스트나 화상, 음성 등이 이에 해당된다.

###금융에서의 데이터 활용 예 
- 대출 업무에서 고객의 신용 평점에 데이터 활용. 
- 증권에서 운용의 포트폴리오 조성
- 보험에서 보험수리에 따른 보혐료 산정
--> 기존에는 구조화 데이터에, 수리 파이낸스나 금융공학 등의 금융 이론에서 연역적으로 접근하는 통계학 기법을 이용해왔다. 하지만 최근에는 연역적 접근이 아닌 데이터로부터 귀납적으로 접근하는 머신러닝 기법을 적용하거나 자연언어 처리 또는 화상처리 기술을 이용하여 지금까지 다루지 않았단 '비구화 데이터'를 활용하고자하는 움직임이 있다.

### 머신러닝이란
주어진 데이터에 잠재된 규칙(패턴)을 기계로 찾아내는 것
해석성(설명성)과 예측(정확도) 중 어느 쪽에 무게를 둘 것인지 선택한다..
해석성이란 주어진 데이터가 어떤 성질을 갖고 무엇을 요인으로 해서 결과를 얻을 수 있는지를 이해하는 것을 목표로 한다. 한편 '예측"이란 과거의 경험으로부터 미래를 말하는 것처럼 과거의 데이터를 학습함으로써 미지의 데이터가 어떤 결과를 가져올 지를 파악하는 데 목표를 둔다.
예를들어 증권 비지니스의 리테일 업무에서 '해석'이란 고객이 금융상품을 구매할 때 고객이 가진 특성 중 어떤 요인이 고객 구매를 유도하는 지를 찾아내는 것. '예측'이란 그 금융상품의 구매확률이 높은 고객을 선별해 내는 것이다.

### 머신러닝 프로젝트의 과정
- 예측에 중점을 둔 머신러닝 모델을 비지니스에 적용하는 프로젝트의 예.

Step 1. 비지니스 이해와 분석 디자인
 비지니스 과제를 이해하고, 이 프로젝트에서 무엇을 실현하고 싶은지 목표를 명확히하고 정량적인 목표치의 설정과 그 접근법을 설계한다.

Step2. 데이터의 수집 이해.
 비지니스 과제를 해결하는 머신러닝 모델구축(모델링)을 위해 데이터 준비와 사전 처리를 실행한다. 이 단계에서 확보한 데이터의 경향을 확인하고 특징량을 설계해, 모델링에 필요한 형식으로 데이터를 만든다. 일반적으로 다른 단계와 비교하자면 이 단계가 가장 손이 많이 가는 작업이다.
 
Step3. 모델링(학습)
비지니스 과제와 데이터에 대응하는 몇 가지 적절한 방법을 선택해, 머신러닝 모델을 구축한다. 대부분의 머신러닝 모델은 구축하기 전에 하이퍼 파라미터라 불리는 설정값을 미리 조정해야 하므로 이 단계에서 분석자가 실행한다.

Step4.  평가, 검증
 - 구축한 모델의 정확도와 추론속도 등이 비지니스 과제를 해결하는 데 충분한 퍼포먼스를 발휘할 지 검증.
 특징량의 재설계와 하이퍼 파라미터 재설정 등의 튜닝 작업을 한다.
 
Step 5,6 적용(deploy) & 모니터링
 
 #머신러닝 모델의 분류

1. 지도학습 -- 회귀, 판별(분류)
2. 비지도 학습 - 클러스터링, 비지도 이상탐지(어노멀리 디텍션)
3. 강화학습

### 지도학습
 지도학습에는 연속 값을 예측하는 회귀 모델과 주어진 클래스마다 데이터를 식별하는 판별 모델이 있다. '결과'와 '요인'의 관련성은 관계성을 나타내는 데이터가 사전에 대량으로 주어짐으로써 패턴으로 학습할 수 있으며, 미지의 데이터가 발생했을 때는 어떤 '결과'가 나올지 예측할 수 있다.
 머신러닝 분야에서 '결과'는 타깃이나 교사 레이블, 목적변수 등으로 부르고, '요인'은 특징량이나 설명변수 등으로 부른다. 지도학습은 이 타깃과 특징량을 쌍으로 가진 데이터를 기반으로 한 머신러닝을 말한다.
 
 * 회귀모델
 타깃이 양적데이터(연속값)인 경우, 회귀모델을 채택한다. 예를들어 기업실적을 예측할 경우, 회귀모델을 사용할 수있다. 매출액을 타깃으로 하고, 그 매출의 변동에는 환율이나 설비투자, 거시 지표 등과 더불어 뉴스나 애널리스트 보고서 같은 텍스트 정보도 특징량이 될 수 있다.
 회귀모델 학습데이터의 예로, 각 종목 레코드의 특징량에는 매출이나 이익 같은 정보를 생각할 수 있고, 타깃은 이들 정보가 공개된 일정 기간 후의 주가이다.
 
 * 판별모델
 타깃이 질적 데이터(클래스, 카테고리)인 경우 판별모델을 채택한다. 주어진 데이터를 여러 클래스(카테고리)로 분류하기 위한 모델이다. 대부분의 판별 모델은 각 클래스의 예측 확률을 출력한다. 그 때문에 예측 결과로 질적 클래스가 필요한 경우에는 적절한 확률의 역치를 설정하고, 예측 확률로부터 예측 클래스를 산출한다. 비지니스 목적에 따라서는 예측의 확률을 스코어로 사용하는 경우도 있다.

## 비지도학습
비지도 학습은 타깃이 사전에 정해지지 않고 특징만을 갖는 데이터에 대해서 그 특징량의 경향을 학습하고 모델화하는 방법이다. 비지도 학습에는 '클러스터링'이나 Anomaly Detection 등의 방법이 있다.
 
* 클러스터링
비슷한 특징량을 가진 데이터를 그룹핑하는 방법을 클러스터링이라고 한다. 비지니스에 활용할 때는 그룹핑한 결과로부터 그룹(클러스터) 별로 시책을 검토한다. 예를들어 은행의 소매 부문의 경우 고객의 연령과 연봉과 같은 기본정보와 더불어 고객의 자녀수, 나이, 주택 담보 대출 상황 등의 정보를 사용해서 클러스터링하고 유사한 고객 그룹별로 적절한 자산 운용 방법을 제안할 수 있다.

클러스터링에는 계층적 클러스터링과 비계층적 클러스터링 2종류가 있다. 계층적 클러스터링은 주어진 데이터와 클러스터와의 관계성을 계층 구조화할 수 있다. 덴드로그램.
사전에 클러스터 수가 정해지지 않아도, 덴드로그램을 보면서 사후에서 클러스터 수를 설정할 수 있다. 

한편 비계층적 클러스터링은 최종적으로 작성하고자 하는 클러스터 수가 미리 정해져 있는 경우에 채택한다. 대표적인 기법이 k-means이다. 작성하고자 하는 클러스터 수와 초깃값을 주고 좌표상 가까운 데이터끼리 묶는다.  계측정 클러스터링 보다 계산량이 적다.

* Anomaly Detection(비지도 학습에 의한 이상탐지)
- 기계고장, 부정한 거래 등 이상을 알리는 기능은 여러가지 상황에서 필요하게 된다. 어떤 역치를 넘어선 상황을 이상이라고 정의할 때 이것을 알리기 프로그램은 쉽게 만들 수 있다. 그러나 CPU의 가동, 메모리 사용량, 디스크 액세스 등 모든 활동 데이터가 복잡하게 얽힌 경우, 이상상황은 그때마다 달라지기 때문에 정의하기 어렵다.
AD(이상탐지)는 비지도학습과 지도학습 쌍방의 접근이 있다. 하지만 이상한 거동이 다양할 경우 비지도 학습에 의한 이상탐지가 자주 채택된다. - 주로 부정거래 탐지. 과거 비적상이 없다고 가정된 거래를 학습하고, 이 패턴으로부터 현저하게 다른 거래량이나 주가 추이를 이상으로 검출하고, 비상대기를 출력하는 구조가 도입되었다.


3. 머신러닝의 평가
 기존의 데이터에 너무 잘 맞으면 미지의 데이터에 대한 예측력이 떨어지는 것을 과적합이라하고, 한정된 기존 데이터를 활용해 어떻게 과적합을 피하고 미지의 데이터에 대한 예측력을 높일지(일반화)가 핵심이다.
 과적합의 주요 원인은 학습 데이터의 양에 비해 예측 모델이 지나치게 복잡하다는 것. 특징량이 학습 데이터에 어떤 특징이 있는지 수치화한 것이 너무 많다는 데 있다. 따라서 예측 모델이 과적합이라는 것을 알면, 특징량을 줄여 모델을 단순하게 하거나 학습 데이터를 늘림으로써 일반화 능력을 향상할 수 있다.
 
 <예측 모델이 과적합인지 확인하는 방법 2가지>
 * 홀드 아웃법
 기존의 데이터를 무작위로 2개로 나누고, 한쪽 데이터를 사용하여 학습하고, 나머지 데이터를 사용하여 테스트 한다. 학습 데이터에 대한 예측정확도보다 테스트 데이터에 대한 예측 정확도가 현저히 낮을 때 모델은 과적합이라고 할 수 있다. 
 보통 학습 데이터와 테스트 데이터는 무작위로 분류한다. 하지만 주가 예측 등 시간의 경과와 함께 구조가 바뀌는 지점을 예측하고 싶을 경우는 예전 데이터를 학습 데이터로 학습하고, 새로운 데이터를 테스트 데이터로 한다.
 
 * 교차 검증법 (Cross-validation)
 홀드아웃은 학습 데이터나 테스트 데이터에 치우침이 있으면 모델 성능에 악영향이 있다. 이를 보충하는 방법이 교차 검증법이다.
 기존의 데이터를 무작위로 K개로 나누고, 그중 1그룹을 테스트 데이터, 남은 K-1개의 그룹을 학습 데이터로 한다. K개로 나눈 학습 데이터와 테스트 데이터 세트를 이용하여 K회 검증을 시행한다. 그렇게 해서 얻은 K회의 예측정확도의 평균을 이 모델의 정확도로 한다. 금융기관 계좌 해약이나 상품의 구매 예측 등 시간 경과에 따라 구조가 별로 변하지 않은 사상을 예측하고 싶은 경우는 교차 검증법으로 검증하는 것이 효과적이다.
 
 1. 판별모델의 정확도 지표는 혼동행렬(Confusion Matrix)라고 불리는 것이다. 혼동행렬은 판별모델을 이용했을 때 분류한(음/양)과 그 실제값(진/위) 에 대해 결과를 정리한 표이다. 예를들어 FP는 포델의 예측은 True이지만 실제 교차는 False이여서 결과적으로 틀린 사례이다.
 
 Precision(정밀도) =TP/TP+FP
 Recall(재현율) = TP/TP+FN
 Accuracy(정확도) = TP+TN/TP+FP+FN+TN
 F-measure : 2*Recall*Precision/Recall+Precision
 
 기업의 도산 위험을 판별하는 모델을 예로든다면,
  Precision정밀도는 파산한다고 예측한 기업이 실제 파산하는 비율.
  Recall은 실제로 파산한 기업 중 모델이 도산한다고 예측할 수 있었던 비율
  Precision과 Recall은 Trade-off상충관계에 있어, 한쪽을 높이면 한쪽은 떨어진다.
  정확도는 전체 속에서 도산한다, 도산하지 않는다를 바르게 판정하는 비율이다. 언뜻보면 만능 평가지표로 보이지만 기업의 도산이 전체의 0.1%로 적을 경우, 모든 기업이 도산하지 않는다고 판정하면 99.9%의 정확도를 가진 모델이라고 평가해 버린다. 이런 경우 Precision과 Recall의 조화 평균인 F-measure를 이용함으로써 치우침이 있는 데이터에도 대응할 수 있다.
  
  회귀모델의 정확도 지표
  - 회귀 모델의 정확도는 RMSE(Root Mean Squared Error, 평균 제곱근 오차)를 많이 사용한다. 평균 제곱근 오차는 모델이 예측한 값과 실제값의 차의 2제곱 평균 제곱근을 계산한 오차이며, 모델의 정확도가 높으면 0에 가깝다. 
  매출 등 백만단위를 가진 타깃을 예측할 경우 평균 제급근 오차는 수십만에서 수백만 값이 된다. 반면 주가 등락률 0.1 정도의 타깃을 예측할 경우 평균 제곱근 오차는 작은 값이 된다. 그런 의미에서 평균 제곱근 오차는 예측 타깃의 단위(분산)을 유지한 평가 지표라 할 수 있다. 한편 그 단위를 삭제(조정)한 것이 결정계수이다.
  결정계수는 예측 모델이 목적 변수를 어느 정도나 설명하고 있는지를 나타내며 1이 최대(모델 예측 결과와 타깃이 완전히 같은 움직임)가 된다.
 추론속도는 예측결과를 산출하는 속도(HFT) 등 고속으로 예측 결과를 출력할 필요가 있는 경우에 중요시한다. 해석성은 예측 결과에 이른 이유를 모델이 알기 쉽게 설명하는 능력이다. 예를들어 마케팅 부서에서 매출을 정확히 예측한다 해도 그 자체에는 의미가 없다. 매출을 예측할 때 어떤 특징량이 효과가 있는지 알아야 매출을 향상시키는 데 필요한 시책이 보인다. 이런 경우 예측 정확도보다 해석성이 중요한 지표가 된다.
 
 ### 선형모델
 다중회귀모델: 타깃이 양적으로(무한대~값) 일때
 로지스틱 회귀 모델: 질적 0or 1 값일때 시그모이드 함수(0~1 범위값으로 변환한다)
 
 * 로지스틱 회귀모델에서는 더미 변수화한 타깃값(0 or 1)에 잘 맞도록 시그모이드 함수를 이용하여 예측값을 0부터 1의 범위 값으로 변환한다. 이 경우 예측값은 타깃이 1이 되는 확률이라고 해석할 수 있다. 선형 모델의 학습(최적화) 이란 예측값과 타깃의 오차가 가장 적은 무게를 구하는 것이다. 직선 하나로 결정 경계를 만들 수 있다.
 
 * 선형 모델은 타깃과 특징량의 관계를 가장 간단하게 표현한 모델의 하나이며, 해석이 쉽다. 각 특징량을 정규화한 경우 무게의 절대값이 그 특징량의 예측에 대한 영향도를 나타내고, 무게의 부호가 영향의 방향을 나타낸다. 예를들어 리테일 업무 등의 매출을 타깃으로 하여 선형 모델을 구축하면(비록 구축하는 것 자체에 사업적 가치가 없어도) 매출에 영향을 주는 특징량을 추출함으로써 마케팅이나. 상품 기획에 대한 활용을 기대할 수 있다. 또한 구현이 쉽고 추론 속도가 짧다는 특징이 있다. 한편 특징량에 무게를 곱한 값의 합으로 예측값을 산출한다는 특징에서 특징량에 이상하거나 크거나 작은값(이상값) 혹은 결손값이 포함되는 경우에는 데이터 석제 보완이 플요하다.
 
 - 선형 모델은 데이터의 특징량 수가 많은 경우 일반화 성능이 떨어진다. 즉 미지의 데이터에 대해서 정확하게 예측할 수 있는 무게를 구하기가 어렵다. 이것은 100개의 변수를 가진 연립 방정식 10개를 푸는 경우, 방정식을 충족시키는 답은 무한히 발견되는 것과 같다.
 
 Feature Selection
 이 문제에 대한 솔루션으로 Lasso(Elastic Net)이 있다. 예측에 기여하지 않는 다고 판단한 Weight값 계수를 0로 하여, 가능한 한 심플한 모델을 구하는 선형모델의 개량방법이다.(사용 안함) 
 
 
decision tree 는 각 특징량의 중요도를 구할 수 있다. 다양한 데이터가 혼재하는 표 형식 데이터를 분석하는 데 매우 큰 이점이 있다. 한편 결정 트리 단독으로는 일반화 성능이 낮은 것으로 알려졌다. 그 때문에 앙상블 학습 결정 트리에 적용하여 일반화 성능을 향상하는 방법이 일반적이다.

- 앙상블 학습은 배깅과 부스팅이 있다. 각 모델에 결정트리를 채택한 모델을 각각 Random forest, Gradient Boosting Decision Tree라고 한다.
RF는 데이터의 일부를 추출한 데이터에서 각각 개별적으로 학습하고 그 다수결(평균)을 예측값으로 하는 모델이다.
GBDT는 처음에 베이스라인이 되는 모델을 생성하고, 이를 개션하도록 새로운 모델을 생성,추가하는 방법이다. 현재모델의 잔차(예측값과 실측값의 차이)를 예측함으로써 그것들을 합친 값이 타깃에 가깝도록 학습을 한다.
학습의 처리 효율 관점에서는 병렬로 모델 학습을 할 수 있는 랜덤포레스트가 우세지만 일반화 성능은 그라데이션 부스팅 디시전 트리가 우세한 경우가 많다. 특히 그라데이션 부스팅 의사결정 트리에 샘플링 정규화를 개선한 XGBoost, LightGBM같은 모델은 일반화 성능의 관점에서는 최첨단 모델이라고 할 수 있다.


